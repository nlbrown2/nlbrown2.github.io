---
Title: "When \"it works on my machine\" is a race condition"
categories:
    - Programming
tags:
    - Debugging
    - C
---
# When "It works on my machine" is a race condition
One day at work, I was debugging a program I wrote. The issue was a classic one- the program worked on one machine, and it didn't on another. This classic problem has led to a rise in utilizing VMs, and more recently containers. However, in this case, a VM or a container wouldn't have helped- the issue was in the performance between the two machines. Let me explain!

## The program
The program I was writing was a benchmark program for the [Userspace RCU](liburcu.org) library. This library implements the [Read-Copy Update](https://ieeexplore.ieee.org/abstract/document/5871597)(RCU) algorithm for userspace programs. My benchmark was using RCU to determine when it is safe to free memory. Specifically, I had multiple reader threads accessing a lock-free hash table. I also had a writer thread making updates to this hash table (inserting and deleting elements). Since the hash table is lock-free, it is safe to have concurrent readers and a writer thread access the hash table at the same time. Normal hash tables don't support this and require locks to ensure either readers are accessing the table or a writer is accessing the table (but not both).

Given there are multiple readers accessing the hash table at the same time the writer is removing an element leads to an interesting problem - how does the writer know when the readers have stopped accessing the element it has removed from the hash table? For example, lets say we had a hash table with three elements in it: [A, B, C] and we had the keys that mapped directly to them: [a, b, c]. So hashmap[a] -> A, hashmap[b] -> B and so on. If a reader has looked up B, then the writer, removes b -> B from the hash table & frees the memory for B, then it isn't safe for the reader to access B anymore (use-after-free error). However, we want the reader to continue using B (it looked it up in the hash table for a reason!). Therefore, we have to wait until the reader is done with B before we can free the memory for that element. Those of you who use garbage-collected languages like Java or Go might recognize this is what GC provides for you- it ensures the element exists as long as there is a referene to it somewhere. RCU is a way of allowing the writer to know when it is safe to reclaim the memory of element B in a performant way.

The benchmark is designed to track, on average, how long Userspace RCU waits before it determines it is safe to reclaim that memory. When I ran it on one machine, the results were pretty good - around X ms on average. When I ran it on another machine, the results were wildly different- they were always the duration of the benchmark. This meant all of the elements were being deleted at the end of the benchmark, despite there being plenty of safe opportunities to free them much earlier than that. So, what was happening, and why was it only on this one machine?

The way RCU has you do things is first the readers have to register themselves and go "online" before they start accessing shared state without a lock. Then, when they drop all references to shared state, the report they are in a "quiescent state."
